{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XuKmj2N8hCfz"},"outputs":[],"source":["from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n","from tensorflow.keras.applications.xception import Xception\n","from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from tensorflow.keras.applications.densenet import DenseNet201\n","from tensorflow.keras.applications.nasnet import NASNetLarge\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","\n","from tensorflow.keras.layers import Input\n","from PIL import Image, ImageDraw, ImageFont\n","import random\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image_dataset_from_directory"]},{"cell_type":"code","source":["\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation, Flatten, Input\n","from keras.models import Model\n","import numpy as np\n","from sklearn import metrics\n","from keras.preprocessing.image import ImageDataGenerator\n","digits = [0, 1, 3, 8]\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"nUBbieP0lrCO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685027984360,"user_tz":-180,"elapsed":26482,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}},"outputId":"755ee192-0023-4207-d501-7033aa6f5514"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Генерируем изображения для каждой цифры и режима\n","for digit in digits:\n","  for i in range(10):\n","    img = np.zeros([100,100,3],dtype=np.uint8)\n","    img.fill(255)\n","    font = cv2.FONT_HERSHEY_SIMPLEX # для текста\n","    # Выбираем случайное место для размещения цифры\n","    x = random.randint(0, 60)\n","    y = random.randint(50, 100)\n","\n","    coord = (x, y)\n","      \n","    # fontScale\n","    fontScale = 2\n","\n","    # Line thickness of 2 px\n","    thickness = 2\n","      \n","    # Using cv2.putText() method\n","    img = cv2.putText(img,str(digit) , coord, font, fontScale, (0, 0, 0), thickness, cv2.LINE_AA)\n","    cv2.imwrite(f'/content/drive/MyDrive/lab12cv/test/20/{digit}/{digit}_vertical_{str(i)}.png', img)\n","\n","\n","for digit in digits:\n","  for i in range(10):\n","    img = np.zeros([100,100,3],dtype=np.uint8)\n","    img.fill(255)\n","    font = cv2.FONT_HERSHEY_SIMPLEX # для текста\n","    # Выбираем случайное место для размещения цифры\n","    x = random.randint(0, 60)\n","    y = random.randint(50, 100)\n","\n","    coord = (x, y)\n","      \n","    # fontScale\n","    fontScale = 2\n","\n","    # Line thickness of 2 px\n","    thickness = 2\n","    img = cv2.putText(img,str(digit) , coord, font, fontScale, (0, 0, 0), thickness, cv2.LINE_AA)\n","    (h, w) = img.shape[:2]\n","    center = (int(w / 2), int(h / 2))\n","    rotation_matrix = cv2.getRotationMatrix2D(center, -90, 1)\n","    \n","    img = cv2.warpAffine(img, rotation_matrix, (w, h))\n","    cv2.imwrite(f'/content/drive/MyDrive/lab12cv/test/20/{digit}/{digit}_gorizontal_{str(i)}.png', img)\n","\n"],"metadata":{"id":"M-CwA9MEdNE-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Xception"],"metadata":{"id":"z27hJDf39gBp"}},{"cell_type":"markdown","source":["## 700/100/20\n","\n","\n","\n","\n"],"metadata":{"id":"7na4jc-ml6I3"}},{"cell_type":"code","source":["datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/700/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vks3vUDOlrEx","outputId":"3c50a668-8313-4da2-8de2-29cd35d95090","executionInfo":{"status":"ok","timestamp":1685029673996,"user_tz":-180,"elapsed":3,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2800 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["# Загрузка предварительно обученной модели Xception\n","model = keras.applications.Xception(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(100, 100, 3)\n",")"],"metadata":{"id":"X_QxQLdyvJy2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685029687563,"user_tz":-180,"elapsed":10283,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}},"outputId":"ae985f0b-863f-4b54-a4f5-0b63ee190005"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83683744/83683744 [==============================] - 5s 0us/step\n"]}]},{"cell_type":"code","source":["# last_layer = model.get_layer('avg_pool').output\n","# x = Flatten(name='flatten')(last_layer)\n","# out = Dense(4, activation='softmax', name='output_layer')(x)\n","# custom_resnet_model = Model(inputs=image_input, outputs=out)\n","# for layer in base_model.layers:\n","#     layer.trainable = False\n","x = model.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(4, activation='softmax')(x)\n","model_ = keras.Model(inputs=model.input, outputs=x)\n","\n","# Замораживание всех слоев, кроме последнего\n","# for layer in model.layers:\n","#     layer.trainable = False\n","for layer in model_.layers[:-1]:\n","  layer.trainable = False\n","model_.layers[-1].trainable"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIbUVhODlrJV","outputId":"ea6e42e5-410a-4e67-a823-54ab715050ab","executionInfo":{"status":"ok","timestamp":1685029687564,"user_tz":-180,"elapsed":3,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["model_.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_.fit(train_generator,  validation_data=val_generator, epochs=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqPW5cPIlrLa","outputId":"0a85579f-c4a5-43d4-f481-933b965385a3","executionInfo":{"status":"ok","timestamp":1685029720985,"user_tz":-180,"elapsed":33423,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","44/44 [==============================] - 19s 167ms/step - loss: 0.6851 - accuracy: 0.8871 - val_loss: 0.3669 - val_accuracy: 0.9900\n","Epoch 2/3\n","44/44 [==============================] - 7s 151ms/step - loss: 0.2774 - accuracy: 0.9968 - val_loss: 0.1994 - val_accuracy: 0.9950\n","Epoch 3/3\n","44/44 [==============================] - 6s 145ms/step - loss: 0.1742 - accuracy: 0.9989 - val_loss: 0.1345 - val_accuracy: 0.9975\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9e6c148ca0>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIoNkv4IlrNn","outputId":"41cc4c04-f137-47d0-f828-cc184e2f0bdf","executionInfo":{"status":"ok","timestamp":1685029720985,"user_tz":-180,"elapsed":4,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 80 images belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["mpg = model_.predict(test_generator, len(test_generator))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Hg4tziblrP7","outputId":"c7b0940b-0df1-44fb-cf99-1df08da932a6","executionInfo":{"status":"ok","timestamp":1685029723616,"user_tz":-180,"elapsed":2633,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["80/80 [==============================] - 3s 11ms/step\n"]}]},{"cell_type":"code","source":["y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n"],"metadata":{"id":"dMQDn0TMlrSM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n"],"metadata":{"id":"jx9C-WzflrUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_t"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SeKTKG8XxWlD","outputId":"95b77239-387a-4293-8678-4fea7394683f","executionInfo":{"status":"ok","timestamp":1685029723617,"user_tz":-180,"elapsed":7,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n","       '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1',\n","       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n","       '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',\n","       '3', '3', '3', '3', '3', '3', '3', '3', '8', '8', '8', '8', '8',\n","       '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8',\n","       '8', '8'], dtype='<U1')"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["y_p"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HmDsgxmxX1j","outputId":"2a36638b-70d2-445f-b746-651989bf5ed5","executionInfo":{"status":"ok","timestamp":1685029723617,"user_tz":-180,"elapsed":5,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n","       '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1',\n","       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n","       '1', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',\n","       '3', '3', '3', '3', '3', '3', '3', '3', '8', '8', '8', '8', '8',\n","       '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8',\n","       '8', '8'], dtype='<U1')"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j650XYEKlrW2","outputId":"1f662558-eb39-4b33-a0e7-9dc17825ed66","executionInfo":{"status":"ok","timestamp":1685029723618,"user_tz":-180,"elapsed":5,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix"],"metadata":{"id":"q8qOhLfTlrZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PcBEfFP3NFZ","outputId":"04ceb902-d06f-4f5c-880e-177b2d4f9ab2","executionInfo":{"status":"ok","timestamp":1685029724081,"user_tz":-180,"elapsed":467,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 400/60/20"],"metadata":{"id":"y_U23fyomQNo"}},{"cell_type":"code","source":["datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/400/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/60/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","# Загрузка предварительно обученной модели Xception\n","model = keras.applications.Xception(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(100, 100, 3)\n",")\n","\n","x = model.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(4, activation='softmax')(x)\n","model_ = keras.Model(inputs=model.input, outputs=x)\n","\n","# Замораживание всех слоев, кроме последнего\n","# for layer in model.layers:\n","#     layer.trainable = False\n","for layer in model_.layers[:-1]:\n","  layer.trainable = False\n","model_.layers[-1].trainable\n","\n","model_.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_.fit(train_generator,  validation_data=val_generator, epochs=10)\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model_.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWno-0bt3onE","outputId":"cfd2ea51-410b-4bca-c9c3-d2c4d1e210fb","executionInfo":{"status":"ok","timestamp":1685029866570,"user_tz":-180,"elapsed":54241,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 images belonging to 4 classes.\n","Found 240 images belonging to 4 classes.\n","Epoch 1/10\n","25/25 [==============================] - 7s 166ms/step - loss: 0.8745 - accuracy: 0.7719 - val_loss: 0.5581 - val_accuracy: 0.9792\n","Epoch 2/10\n","25/25 [==============================] - 3s 130ms/step - loss: 0.4192 - accuracy: 0.9937 - val_loss: 0.3265 - val_accuracy: 0.9875\n","Epoch 3/10\n","25/25 [==============================] - 4s 150ms/step - loss: 0.2703 - accuracy: 0.9962 - val_loss: 0.2276 - val_accuracy: 0.9917\n","Epoch 4/10\n","25/25 [==============================] - 3s 133ms/step - loss: 0.1982 - accuracy: 0.9975 - val_loss: 0.1759 - val_accuracy: 0.9917\n","Epoch 5/10\n","25/25 [==============================] - 3s 135ms/step - loss: 0.1569 - accuracy: 0.9981 - val_loss: 0.1428 - val_accuracy: 0.9958\n","Epoch 6/10\n","25/25 [==============================] - 6s 235ms/step - loss: 0.1292 - accuracy: 0.9987 - val_loss: 0.1200 - val_accuracy: 0.9958\n","Epoch 7/10\n","25/25 [==============================] - 4s 152ms/step - loss: 0.1097 - accuracy: 0.9994 - val_loss: 0.1033 - val_accuracy: 0.9958\n","Epoch 8/10\n","25/25 [==============================] - 3s 138ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 1.0000\n","Epoch 9/10\n","25/25 [==============================] - 4s 174ms/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 1.0000\n","Epoch 10/10\n","25/25 [==============================] - 4s 166ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 2s 10ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["#№ 250/30/20\n"],"metadata":{"id":"mbLpmq_YmtHA"}},{"cell_type":"code","source":["datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/250/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/30/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","# Загрузка предварительно обученной модели Xception\n","model = keras.applications.Xception(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(100, 100, 3)\n",")\n","\n","x = model.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(4, activation='softmax')(x)\n","model_ = keras.Model(inputs=model.input, outputs=x)\n","\n","# Замораживание всех слоев, кроме последнего\n","# for layer in model.layers:\n","#     layer.trainable = False\n","for layer in model_.layers[:-1]:\n","  layer.trainable = False\n","model_.layers[-1].trainable\n","\n","model_.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_.fit(train_generator,  validation_data=val_generator, epochs=10)\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model_.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"evI58fJX4_Mj","outputId":"ae64c515-a2f2-4605-da93-96f8d307af3f","executionInfo":{"status":"ok","timestamp":1685030014445,"user_tz":-180,"elapsed":36208,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 images belonging to 4 classes.\n","Found 120 images belonging to 4 classes.\n","Epoch 1/10\n","16/16 [==============================] - 9s 283ms/step - loss: 1.0547 - accuracy: 0.6320 - val_loss: 0.7517 - val_accuracy: 0.9500\n","Epoch 2/10\n","16/16 [==============================] - 2s 139ms/step - loss: 0.6235 - accuracy: 0.9720 - val_loss: 0.4796 - val_accuracy: 1.0000\n","Epoch 3/10\n","16/16 [==============================] - 2s 133ms/step - loss: 0.4225 - accuracy: 0.9870 - val_loss: 0.3459 - val_accuracy: 1.0000\n","Epoch 4/10\n","16/16 [==============================] - 2s 139ms/step - loss: 0.3191 - accuracy: 0.9890 - val_loss: 0.2685 - val_accuracy: 1.0000\n","Epoch 5/10\n","16/16 [==============================] - 2s 143ms/step - loss: 0.2564 - accuracy: 0.9900 - val_loss: 0.2185 - val_accuracy: 1.0000\n","Epoch 6/10\n","16/16 [==============================] - 2s 137ms/step - loss: 0.2144 - accuracy: 0.9930 - val_loss: 0.1842 - val_accuracy: 1.0000\n","Epoch 7/10\n","16/16 [==============================] - 2s 149ms/step - loss: 0.1843 - accuracy: 0.9950 - val_loss: 0.1584 - val_accuracy: 1.0000\n","Epoch 8/10\n","16/16 [==============================] - 2s 132ms/step - loss: 0.1613 - accuracy: 0.9950 - val_loss: 0.1385 - val_accuracy: 1.0000\n","Epoch 9/10\n","16/16 [==============================] - 2s 130ms/step - loss: 0.1437 - accuracy: 0.9950 - val_loss: 0.1227 - val_accuracy: 1.0000\n","Epoch 10/10\n","16/16 [==============================] - 2s 146ms/step - loss: 0.1288 - accuracy: 0.9960 - val_loss: 0.1104 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 2s 10ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 100/15/20"],"metadata":{"id":"g7-CsHBvnELk"}},{"cell_type":"code","source":["datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/15/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","# Загрузка предварительно обученной модели Xception\n","model = keras.applications.Xception(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(100, 100, 3)\n",")\n","\n","x = model.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(4, activation='softmax')(x)\n","model_ = keras.Model(inputs=model.input, outputs=x)\n","\n","# Замораживание всех слоев, кроме последнего\n","# for layer in model.layers:\n","#     layer.trainable = False\n","for layer in model_.layers[:-1]:\n","  layer.trainable = False\n","model_.layers[-1].trainable\n","\n","model_.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_.fit(train_generator,  validation_data=val_generator, epochs=3)\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model_.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4u39tzP6IyR","outputId":"f4b966f4-a1eb-4c8a-b30d-0c8f425bcc94","executionInfo":{"status":"ok","timestamp":1685030087031,"user_tz":-180,"elapsed":10847,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400 images belonging to 4 classes.\n","Found 60 images belonging to 4 classes.\n","Epoch 1/3\n","7/7 [==============================] - 5s 370ms/step - loss: 1.1945 - accuracy: 0.5400 - val_loss: 0.9848 - val_accuracy: 0.7667\n","Epoch 2/3\n","7/7 [==============================] - 1s 124ms/step - loss: 0.9298 - accuracy: 0.8650 - val_loss: 0.7579 - val_accuracy: 0.9667\n","Epoch 3/3\n","7/7 [==============================] - 1s 132ms/step - loss: 0.7235 - accuracy: 0.9950 - val_loss: 0.5984 - val_accuracy: 0.9667\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 1s 10ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.95      1.00      0.98        20\n","           1       0.95      1.00      0.98        20\n","           3       1.00      0.95      0.97        20\n","           8       1.00      0.95      0.97        20\n","\n","    accuracy                           0.97        80\n","   macro avg       0.98      0.98      0.97        80\n","weighted avg       0.98      0.97      0.97        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  1 19  0]\n"," [ 1  0  0 19]]\n"]}]},{"cell_type":"markdown","source":["# ResNet"],"metadata":{"id":"53uqlLFR9Uzx"}},{"cell_type":"markdown","source":["#№ 700/100/20"],"metadata":{"id":"wjvyeu7cnxvI"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/700/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = ResNet152V2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5aE98VlJoR6","outputId":"21e3ca9c-f36c-44a2-8853-3b19d141e4d0","executionInfo":{"status":"ok","timestamp":1685030246138,"user_tz":-180,"elapsed":81923,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2800 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","234545216/234545216 [==============================] - 12s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-34-aec75c70843b>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","44/44 [==============================] - 30s 382ms/step - loss: 0.4729 - accuracy: 0.9364 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 2/3\n","44/44 [==============================] - 10s 237ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 1.6612e-06 - val_accuracy: 1.0000\n","Epoch 3/3\n","44/44 [==============================] - 9s 208ms/step - loss: 8.5611e-04 - accuracy: 0.9996 - val_loss: 1.4645e-05 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 6s 25ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 400/60/20"],"metadata":{"id":"NORyOTIrn_AD"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/400/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/60/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = ResNet152V2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=10,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDUFu55gR-9L","outputId":"5adc6914-39a4-4513-8995-17fa83e0fee5","executionInfo":{"status":"ok","timestamp":1685030316353,"user_tz":-180,"elapsed":70217,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 images belonging to 4 classes.\n","Found 240 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-35-5bd7509c8b2d>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=10,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","25/25 [==============================] - 16s 255ms/step - loss: 0.4887 - accuracy: 0.9225 - val_loss: 0.0060 - val_accuracy: 0.9958\n","Epoch 2/10\n","25/25 [==============================] - 4s 167ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.2620e-06 - val_accuracy: 1.0000\n","Epoch 3/10\n","25/25 [==============================] - 4s 145ms/step - loss: 0.0015 - accuracy: 0.9987 - val_loss: 2.9385e-06 - val_accuracy: 1.0000\n","Epoch 4/10\n","25/25 [==============================] - 4s 147ms/step - loss: 4.3811e-04 - accuracy: 1.0000 - val_loss: 9.8138e-07 - val_accuracy: 1.0000\n","Epoch 5/10\n","25/25 [==============================] - 4s 155ms/step - loss: 3.2918e-05 - accuracy: 1.0000 - val_loss: 4.9916e-07 - val_accuracy: 1.0000\n","Epoch 6/10\n","25/25 [==============================] - 4s 148ms/step - loss: 2.1788e-05 - accuracy: 1.0000 - val_loss: 3.8493e-07 - val_accuracy: 1.0000\n","Epoch 7/10\n","25/25 [==============================] - 4s 147ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 1.4901e-09 - val_accuracy: 1.0000\n","Epoch 8/10\n","25/25 [==============================] - 4s 156ms/step - loss: 3.9514e-05 - accuracy: 1.0000 - val_loss: 1.8378e-08 - val_accuracy: 1.0000\n","Epoch 9/10\n","25/25 [==============================] - 4s 151ms/step - loss: 2.4942e-04 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n","Epoch 10/10\n","25/25 [==============================] - 4s 150ms/step - loss: 2.7369e-06 - accuracy: 1.0000 - val_loss: 1.9868e-09 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 5s 33ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["#№ 250/30/20"],"metadata":{"id":"-_VcQeGqoNEE"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/250/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/30/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = ResNet152V2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9vLSLDpUDmx","outputId":"97fba3d9-ff12-4e52-a425-e1c6e5fee074","executionInfo":{"status":"ok","timestamp":1685031492784,"user_tz":-180,"elapsed":50923,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 images belonging to 4 classes.\n","Found 120 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-36-e2fac2dda3ec>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","16/16 [==============================] - 23s 673ms/step - loss: 0.7672 - accuracy: 0.8720 - val_loss: 2.6247e-05 - val_accuracy: 1.0000\n","Epoch 2/3\n","16/16 [==============================] - 3s 182ms/step - loss: 0.0414 - accuracy: 0.9940 - val_loss: 5.9604e-08 - val_accuracy: 1.0000\n","Epoch 3/3\n","16/16 [==============================] - 3s 181ms/step - loss: 0.0175 - accuracy: 0.9970 - val_loss: 3.1789e-08 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 8s 33ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 100/15/20"],"metadata":{"id":"YkYLeytSs4Qj"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/15/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = ResNet152V2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SX-oLRQrUZ4e","outputId":"27e4e669-1bbe-4423-ec4b-bac6892fbf85","executionInfo":{"status":"ok","timestamp":1685031559798,"user_tz":-180,"elapsed":38190,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400 images belonging to 4 classes.\n","Found 60 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-37-7475c6ff41b0>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","7/7 [==============================] - 22s 997ms/step - loss: 1.8594 - accuracy: 0.7225 - val_loss: 0.0058 - val_accuracy: 1.0000\n","Epoch 2/3\n","7/7 [==============================] - 1s 155ms/step - loss: 0.0548 - accuracy: 0.9775 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 3/3\n","7/7 [==============================] - 1s 153ms/step - loss: 0.0256 - accuracy: 0.9875 - val_loss: 1.2889e-04 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 6s 28ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["# InceptionResNetV2"],"metadata":{"id":"-ggUzySeWYTK"}},{"cell_type":"markdown","source":["#№ 700/100/200"],"metadata":{"id":"BH-BY3uktLCW"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/700/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = InceptionResNetV2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHMLcXtqUqBl","outputId":"0d27678c-0c7a-49a2-d546-863cfb4857a7","executionInfo":{"status":"ok","timestamp":1685031666948,"user_tz":-180,"elapsed":79949,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2800 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","219055592/219055592 [==============================] - 11s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-38-5ec9112fe5eb>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","44/44 [==============================] - 27s 279ms/step - loss: 0.2371 - accuracy: 0.9286 - val_loss: 0.0688 - val_accuracy: 0.9900\n","Epoch 2/3\n","44/44 [==============================] - 7s 160ms/step - loss: 0.0619 - accuracy: 0.9854 - val_loss: 0.0485 - val_accuracy: 0.9875\n","Epoch 3/3\n","44/44 [==============================] - 9s 189ms/step - loss: 0.0437 - accuracy: 0.9900 - val_loss: 0.0342 - val_accuracy: 0.9925\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 8s 41ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 400/60/20"],"metadata":{"id":"3Vxr9FRbtli-"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/400/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/60/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = InceptionResNetV2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGgmPTrpWtCc","outputId":"6c4b8575-d780-46d7-e4a4-d8c175b8c73b","executionInfo":{"status":"ok","timestamp":1685031738681,"user_tz":-180,"elapsed":55671,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 images belonging to 4 classes.\n","Found 240 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-39-bfc8d667681a>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","25/25 [==============================] - 28s 448ms/step - loss: 0.3103 - accuracy: 0.9019 - val_loss: 0.0952 - val_accuracy: 0.9833\n","Epoch 2/3\n","25/25 [==============================] - 4s 155ms/step - loss: 0.0781 - accuracy: 0.9831 - val_loss: 0.0600 - val_accuracy: 0.9875\n","Epoch 3/3\n","25/25 [==============================] - 4s 157ms/step - loss: 0.0520 - accuracy: 0.9862 - val_loss: 0.0508 - val_accuracy: 0.9833\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 8s 33ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 250/30/20"],"metadata":{"id":"U0m4kjbAtZKK"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/250/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/30/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = InceptionResNetV2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YzjTfpXXgsb","outputId":"bcd74c5f-363f-436a-ea17-cd7b7a1056ec","executionInfo":{"status":"ok","timestamp":1685031791310,"user_tz":-180,"elapsed":52642,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 images belonging to 4 classes.\n","Found 120 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-ce59e449dc60>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","16/16 [==============================] - 29s 574ms/step - loss: 0.4190 - accuracy: 0.8650 - val_loss: 0.1134 - val_accuracy: 0.9917\n","Epoch 2/3\n","16/16 [==============================] - 2s 131ms/step - loss: 0.1032 - accuracy: 0.9780 - val_loss: 0.0685 - val_accuracy: 1.0000\n","Epoch 3/3\n","16/16 [==============================] - 2s 134ms/step - loss: 0.0734 - accuracy: 0.9900 - val_loss: 0.0554 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 6s 29ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 100/15/20"],"metadata":{"id":"RAFgj177t6GC"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/15/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = InceptionResNetV2(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"960ORPI4Xvu5","outputId":"b4041616-b711-4fd9-c72e-07f395e48dcd","executionInfo":{"status":"ok","timestamp":1685031837566,"user_tz":-180,"elapsed":46267,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400 images belonging to 4 classes.\n","Found 60 images belonging to 4 classes.\n","Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-41-a409bb69c46f>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 25s 2s/step - loss: 0.7522 - accuracy: 0.7475 - val_loss: 0.2912 - val_accuracy: 0.9500\n","Epoch 2/3\n","7/7 [==============================] - 1s 151ms/step - loss: 0.2018 - accuracy: 0.9550 - val_loss: 0.1987 - val_accuracy: 0.9500\n","Epoch 3/3\n","7/7 [==============================] - 1s 150ms/step - loss: 0.1485 - accuracy: 0.9675 - val_loss: 0.1577 - val_accuracy: 0.9500\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 10s 42ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["# DenseNet201"],"metadata":{"id":"xDiZha0AYMlw"}},{"cell_type":"markdown","source":["## 700/100/20"],"metadata":{"id":"zJHPD0ZZuPK4"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/700/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = DenseNet201(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrUJg2G9YNiI","outputId":"5ae7301a-dfd9-4ebb-a1a6-735e777e1518","executionInfo":{"status":"ok","timestamp":1685031918941,"user_tz":-180,"elapsed":72576,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2800 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n","74836368/74836368 [==============================] - 4s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-42-201ce8ab2cdc>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","44/44 [==============================] - 32s 344ms/step - loss: 0.1421 - accuracy: 0.9654 - val_loss: 6.2585e-09 - val_accuracy: 1.0000\n","Epoch 2/3\n","44/44 [==============================] - 7s 164ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.3113e-08 - val_accuracy: 1.0000\n","Epoch 3/3\n","44/44 [==============================] - 7s 157ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.6822e-09 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 6s 19ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 400/60/20"],"metadata":{"id":"hK0-cH27uYCH"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/400/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/60/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = DenseNet201(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-EF7GQELYdXK","outputId":"e39f7fd5-cd06-4dbe-c1b3-aa51b3bff858","executionInfo":{"status":"ok","timestamp":1685031993487,"user_tz":-180,"elapsed":52340,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 images belonging to 4 classes.\n","Found 240 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-43-ed30a322884f>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","25/25 [==============================] - 25s 360ms/step - loss: 0.1977 - accuracy: 0.9362 - val_loss: 3.1767e-06 - val_accuracy: 1.0000\n","Epoch 2/3\n","25/25 [==============================] - 3s 136ms/step - loss: 0.0015 - accuracy: 0.9987 - val_loss: 2.4835e-09 - val_accuracy: 1.0000\n","Epoch 3/3\n","25/25 [==============================] - 3s 136ms/step - loss: 2.1475e-04 - accuracy: 1.0000 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 6s 22ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["#№ 250/30/20"],"metadata":{"id":"Ya5jgj9EuvvA"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/250/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/30/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = DenseNet201(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1PP_UQJJYilX","outputId":"9fba0639-b873-4324-f075-7a13b91aa227","executionInfo":{"status":"ok","timestamp":1685032093889,"user_tz":-180,"elapsed":65166,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 images belonging to 4 classes.\n","Found 120 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-44-c5f7f3582344>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","16/16 [==============================] - 32s 962ms/step - loss: 0.4024 - accuracy: 0.8820 - val_loss: 0.0018 - val_accuracy: 1.0000\n","Epoch 2/3\n","16/16 [==============================] - 3s 170ms/step - loss: 0.0044 - accuracy: 0.9970 - val_loss: 2.9802e-09 - val_accuracy: 1.0000\n","Epoch 3/3\n","16/16 [==============================] - 3s 201ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 10s 44ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 100/15/20"],"metadata":{"id":"S67nqbUCvIUi"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/15/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = DenseNet201(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08oAvCeoYlHd","outputId":"e0ac0fee-5770-4d67-b012-f258bfe06558","executionInfo":{"status":"ok","timestamp":1685032134318,"user_tz":-180,"elapsed":40433,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400 images belonging to 4 classes.\n","Found 60 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-45-f7d53e2a4c09>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","7/7 [==============================] - 22s 1s/step - loss: 2.1065 - accuracy: 0.6200 - val_loss: 0.0236 - val_accuracy: 1.0000\n","Epoch 2/3\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0819 - accuracy: 0.9775 - val_loss: 1.3259e-05 - val_accuracy: 1.0000\n","Epoch 3/3\n","7/7 [==============================] - 1s 135ms/step - loss: 0.0337 - accuracy: 0.9925 - val_loss: 2.2444e-05 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 4s 20ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      0.95      0.97        20\n","           3       0.95      1.00      0.98        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           0.99        80\n","   macro avg       0.99      0.99      0.99        80\n","weighted avg       0.99      0.99      0.99        80\n","\n","[[20  0  0  0]\n"," [ 0 19  1  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["# NASNetLarge"],"metadata":{"id":"TACC9PXAZClB"}},{"cell_type":"markdown","source":["## 700/100/20"],"metadata":{"id":"of-TzAylvXVl"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/700/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = NASNetLarge(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZ48RQ2cZE5G","outputId":"c94f04a4-5269-48bf-d725-37a9a5571301","executionInfo":{"status":"ok","timestamp":1685032331435,"user_tz":-180,"elapsed":149365,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2800 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n","343610240/343610240 [==============================] - 16s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-46-ddb18fe269cb>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","44/44 [==============================] - 61s 689ms/step - loss: 0.1498 - accuracy: 0.9529 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 2/3\n","44/44 [==============================] - 12s 278ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 6.9373e-04 - val_accuracy: 1.0000\n","Epoch 3/3\n","44/44 [==============================] - 12s 272ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 4.3462e-04 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 14s 59ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 400/60/20"],"metadata":{"id":"PDzv2zXVvq83"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/400/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/60/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = NASNetLarge(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EK3W7oLAZFAY","outputId":"7de5231b-0b84-4d80-de07-569fe0df52fd","executionInfo":{"status":"ok","timestamp":1685032414580,"user_tz":-180,"elapsed":83149,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 images belonging to 4 classes.\n","Found 240 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-47-2b934c077d15>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","25/25 [==============================] - 31s 493ms/step - loss: 0.2053 - accuracy: 0.9294 - val_loss: 0.0046 - val_accuracy: 1.0000\n","Epoch 2/3\n","25/25 [==============================] - 6s 250ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 8.3480e-04 - val_accuracy: 1.0000\n","Epoch 3/3\n","25/25 [==============================] - 6s 253ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7353e-04 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 8s 30ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 250/30/20"],"metadata":{"id":"Njoylg1Lv20w"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/250/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/30/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = NASNetLarge(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SO_t82OKZFGj","outputId":"b79e4d2a-2bb2-4b55-f02f-4352fce0a208","executionInfo":{"status":"ok","timestamp":1685032477479,"user_tz":-180,"elapsed":62911,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 images belonging to 4 classes.\n","Found 120 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-48-b15e1157b526>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","16/16 [==============================] - 29s 709ms/step - loss: 0.4010 - accuracy: 0.8570 - val_loss: 0.0158 - val_accuracy: 1.0000\n","Epoch 2/3\n","16/16 [==============================] - 4s 255ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.0031 - val_accuracy: 1.0000\n","Epoch 3/3\n","16/16 [==============================] - 4s 251ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 8s 34ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]},{"cell_type":"markdown","source":["## 100/15/20"],"metadata":{"id":"vkaBH5GYv_xg"}},{"cell_type":"code","source":["img_width, img_height = 100, 100\n","\n","input_shape = (img_width, img_height, 3) # 3 - channels_last\n","# Размер мини-выборки\n","batch_size = 8\n","# Количество изображений для обучения\n","nb_train_samples = 100\n","# Количество изображений для проверки\n","nb_validation_samples = 14\n","# Количество изображений для тестирования\n","nb_test_samples = 20\n","\n","datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/train/100/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","val_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/valid/15/', target_size=(100, 100), batch_size=64, class_mode='categorical')\n","\n","\n","vgg16_net = NASNetLarge(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\n","vgg16_net.trainable = False\n","\n","model = Sequential()\n","model.add(vgg16_net) \n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","\n","model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n","\n","test_generator = datagen.flow_from_directory('/content/drive/MyDrive/lab12cv/test/20/', target_size=(100, 100), batch_size=1, class_mode='categorical', shuffle=False)\n","mpg = model.predict(test_generator, len(test_generator))\n","y_test = test_generator.classes\n","y_pred = np.array([np.argmax(mpg[i,:]) for i in range(mpg.shape[0])])\n","\n","cl_names = list(train_generator.class_indices)\n","y_t = np.array(cl_names)[y_test]\n","y_p = np.array(cl_names)[y_pred]\n","mtrs = metrics.classification_report(y_t, y_p)\n","print(mtrs)\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(confusion_matrix(y_t, y_p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ha8ZuN9yZFLK","outputId":"c5136b03-ac85-4da8-d3c4-eca8d8b7d774","executionInfo":{"status":"ok","timestamp":1685032531055,"user_tz":-180,"elapsed":53585,"user":{"displayName":"Серафим Серов","userId":"13616652700156874798"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400 images belonging to 4 classes.\n","Found 60 images belonging to 4 classes.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-49-3e21cf7fd243>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(train_generator,epochs=3,validation_data=val_generator)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","7/7 [==============================] - 28s 2s/step - loss: 0.6693 - accuracy: 0.7325 - val_loss: 0.0581 - val_accuracy: 1.0000\n","Epoch 2/3\n","7/7 [==============================] - 2s 247ms/step - loss: 0.1008 - accuracy: 0.9775 - val_loss: 0.0097 - val_accuracy: 1.0000\n","Epoch 3/3\n","7/7 [==============================] - 2s 270ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n","Found 80 images belonging to 4 classes.\n","80/80 [==============================] - 9s 36ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        20\n","           1       1.00      1.00      1.00        20\n","           3       1.00      1.00      1.00        20\n","           8       1.00      1.00      1.00        20\n","\n","    accuracy                           1.00        80\n","   macro avg       1.00      1.00      1.00        80\n","weighted avg       1.00      1.00      1.00        80\n","\n","[[20  0  0  0]\n"," [ 0 20  0  0]\n"," [ 0  0 20  0]\n"," [ 0  0  0 20]]\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["z27hJDf39gBp"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}